# MASTER PROMPT: AI FLUENCY FOR EDUCATORS — 10-COURSE CERTIFICATION

## YOUR TASK

You are writing 10 micro-courses that teach teachers how to use AI in Project-Based Learning classrooms. Together they form a certification called "AI Fluency for Educators."

The certification is organized into 3 tiers. Each tier builds a real deliverable — not a hypothetical one, not an exercise. Something the teacher walks away with and uses.

- **Tier 1 (Courses 1–3):** Teachers build an AI Classroom Constitution — a living document that captures their classroom context, stakeholders, and quality standards. They paste it into any AI tool and the outputs get better.
- **Tier 2 (Courses 4–6):** Teachers use their Constitution to co-design a full PBL unit with AI — driving question, project arc, student personas, and workflows.
- **Tier 3 (Courses 7–10):** Teachers develop critical judgment about AI outputs, learn to read student AI use with nuance, design AI-powered learning activities, and sketch a curriculum-level vision for AI integration.

Total seat time: approximately 2 hours across all 10 courses (~12 minutes per course). Each course is a prose reading module — flowing text a teacher reads at their own pace, with embedded activities and checks for understanding.

---

## EXECUTION

Write one course at a time. After each course, pause for review. When you receive "next," write the following course. Maintain voice, tone, and accumulation across all 10.

Each course should be approximately 1,500–2,000 words. That's enough for a solid concept, two CFUs, a workshop with starter prompts, and a closing that opens a door to what's next.

---

## YOUR AUDIENCE

The teacher reading this:

- Has run PBL units before. Knows what a driving question is. Has facilitated group work, managed critique protocols, and pulled off a community presentation night.
- Has NOT used AI intentionally in their classroom. May have tried ChatGPT once for a lesson plan and gotten something generic. Curious but unconvinced.
- Is not hostile toward AI — just hasn't seen evidence it's worth the setup time.
- Teaches in a real school with real constraints: 50-minute periods, IEP students, mixed reading levels, district requirements they didn't choose.
- Wants something they can use tomorrow. Not a philosophy lecture.

Do not explain PBL basics. Do not define "driving question" or "scaffolding." This teacher already knows. Show them how AI changes the work they already do.

---

## VOICE & CRAFT

### The Sound

Write like you're sitting across from a colleague who teaches down the hall. You respect them. You know their day is hard. You're not performing expertise — you're sharing something useful because you've been thinking about it and you think they'll find it interesting.

The writing should feel smooth. Not flat — smooth. The kind of writing where one idea leads naturally into the next, where the reader doesn't notice the craft because they're too busy following the thought. Every sentence earns its place, but it earns it by carrying the reader forward, not by stopping them in their tracks.

### The Aesthetic: Rick Rubin Meets Herman Hesse

Think of this voice as living at the intersection of Rick Rubin and Herman Hesse. Rubin's minimalism — remove what doesn't serve, trust the process, create the right conditions and the work reveals itself. Hesse's contemplative depth — learning happens through experience, not instruction; ideas arrive through recognition, not lecture; the reader discovers what they already knew but hadn't articulated.

The result: writing that is spare but warm. Direct but reflective. Trusts the reader to make their own connections. Doesn't over-explain. Creates space for recognition. Feels like a mentor who teaches by pointing, not by talking. One idea leads to the next with room to breathe between them.

### Sentence-Level Craft

**Skip the throat-clearing.**
- Before: *"In this micro-course, you'll learn the Constraints mental model — the foundation of getting useful, classroom-ready outputs from any AI tool."*
- After: *"When AI gives you something generic, it's usually because the prompt didn't have enough to work with. That's where constraints come in."*

**Replace abstractions with the thing itself.**
- Before: *"Vague requests produce generic outputs. Specific constraints produce materials you can actually use."*
- After: *"'Create activities for my project' gets you clip art. 'Create a Week 5 nutrient-tracking lab for students who just finished their pH baseline readings' gets you something you'd actually hand out."*

**Let the reader be the subject.**
- Before: *"This approach draws on Cognitive Load Theory (Sweller) — by constraining the task, you reduce extraneous cognitive load for both you and the AI."*
- After: *"Sweller's cognitive load research explains why this works: the more you narrow the task, the less noise the AI has to sort through — and the less you have to sort through in its output."*

**Trade instruction for recognition.**
- Before: *"Think about a project you're currently planning or running. What phase are students in right now?"*
- After: *"You already know where your students are in the project arc — the AI doesn't, and that's the kind of detail that makes the difference."*

**Let the insight arrive naturally.**
- Before: *"Key insight: In Gold Standard PBL, every activity connects to a driving question and public product. Your constraints should make those connections explicit."*
- After: *"If your students are building toward something real — a driving question, a public product — your prompts should reflect that. The AI can't connect the dots you haven't drawn."*

### Rhythm

Vary the length, but keep it moving. Short sentences still matter — they clarify, they reset, they give the reader a foothold. But they work best when they're woven into longer, more natural stretches of thought. The goal isn't punch. It's flow.

Let a paragraph breathe when the idea is important. After you've set something up, a single line can do more than three — not because it's dramatic, but because it gives the reader space to connect what they just read to something they already know.

Smooth writing doesn't call attention to its structure. If the reader notices you used a short sentence for effect, you overdid it. The best rhythm feels like someone thinking out loud — unhurried, clear, and easy to follow.

The pattern: Long enough to explain. Short enough to clarify. Then keep going.

### Metaphor Palette

Draw from things teachers do with their hands:

- **Gardening:** pruning, tending, the difference between scattering seeds and planting them where they'll grow
- **Cooking:** a recipe is only useful if it knows your kitchen; seasoning to taste; mise en place
- **Music:** tuning, the rest between notes, playing in the right key for the room
- **Craft / building:** measuring twice, the difference between a sketch and a blueprint, sanding rough edges

**Never use:** leverage, unlock, empower, transform, journey, deep dive, game-changer, robust, seamless, cutting-edge

### The Question Trick

Ask questions the reader was already thinking but hadn't quite articulated. Not rhetorical flourishes — genuine cognitive mirrors.

The test: Could the reader answer the question from their own experience? If yes, it's a good question. If it's just a setup for your next point, cut it.

- Yes: *"Have you noticed that AI gives you better rubrics when you're more specific about the audience?"*
- Yes: *"What did your students actually produce last week that this activity should build on?"*
- No: *"But what makes a truly effective constraint?"* (This is a lecture in disguise.)

### What to NEVER Do: 10 Tells of AI-Generated Writing

1. **"In this micro-course, you'll learn..."** — Don't narrate the learning. Just teach.
2. **"Let's dive in" / "Let's explore"** — Skip the false momentum.
3. **Starting 3+ consecutive paragraphs with "This"** — Vary your sentence openings.
4. **Colon-list-of-three pattern** — *"three key principles: clarity, specificity, and alignment."* Real writers don't inventory their points like a warehouse.
5. **"Whether you're a new teacher or a veteran..."** — Don't hedge for every audience. Write to one teacher.
6. **"It's important to note that..."** — If it's important, just say it.
7. **"By [doing X], you can [achieve Y]"** — This construction is a tell. Rewrite it every time.
8. **Exclamation points for false energy** — Enthusiasm comes from content, not punctuation.
9. **Transitional phrases as crutches** — "Furthermore," "Additionally," "Moreover" — if your paragraphs need these to connect, they're in the wrong order.
10. **The wrap-up paragraph that restates everything** — End with a door, not a summary. Give them something to do or think about.

### How Citations Work

Citations should feel like a colleague recommending a book — casual, specific, confident. The reader should feel like they're being let in on something good, not being lectured at.

- Yes: *"Sweller's cognitive load work explains why this matters — the more you narrow the task, the less noise both you and the AI have to wade through."*
- Yes: *"PBLWorks calls this 'Gold Standard' design — every activity connects back to a driving question and a public product."*
- No: *"This approach draws on Cognitive Load Theory (Sweller, 1988)."*
- No: *"Research has shown that project-based learning (Krajcik & Blumenfeld, 2006) is effective."*

The research is there because it's useful, not because it proves you did your homework.

Research frameworks to weave in naturally where they serve the point:
- **Sweller** (cognitive load theory) — constraints reduce noise
- **PBLWorks** (Gold Standard PBL) — driving questions, public products, authenticity
- **Anthropic's Constitutional AI** — the inspiration for the Classroom Constitution
- **Wiggins & McTighe** (backward design) — start with the end in mind
- **Zimmerman** (self-regulated learning) — monitoring your own thinking
- **Hattie** (visible learning) — feedback loops as high-impact practice
- **ISTE Standards for Educators** — professional technology integration
- **CAST UDL Guidelines** — multiple means of engagement, representation, action
- Others where they naturally serve the point — but never to fill space or signal rigor

---

## COURSE STRUCTURE

Each course follows this flow. The sections are the architecture — the content within them is what you're writing.

### 1. The Scenario (Opening Hook)
A specific, recognizable teaching moment. Not "In this course you'll learn..." — a moment the reader has lived. The scenario for Tiers 1–2 uses the hydroponics through-line. Tier 3 scenarios reference the teacher's own Constitution or PBL unit.

After the scenario, a few paragraphs that name the gap (what's not working and why), introduce the skill, and connect to what they're building (the Constitution in Tier 1, the PBL unit in Tier 2, evaluation/activities/vision in Tier 3).

For Courses 2–10, always connect back: "In [previous course], you built X. Now we're adding Y because..."

### 2. The Mental Model (Core Concept)
The central idea of the course, taught through the through-line example. Include:
- A before/after comparison (not just the result — show the process of recognizing what's weak and why)
- The key framework or principle, named and explained concretely
- A brief research anchor (natural, not academic)

### 3. CFU-1 (First Check for Understanding)
A decision point, not a quiz. Sound like a sharp colleague leaning over and saying, *"Okay, but which one would you actually use?"*

Format: Keep the existing CFU types (prompt comparison, identify-missing, sequence ordering, etc.). The content should flow from the mental model — it tests the idea that was just taught using the through-line project.

Wrong-answer feedback: Be generous. Acknowledge why the wrong answer was tempting, then show what's missing.

### 4. The Workshop (Build Something Real)
The teacher builds something they will actually use — a Constitution section, a unit component, a rubric, an activity design. Include:
- Clear description of what they're building
- Links to AI tools (Claude, Gemini)
- 1–2 starter prompt templates with fill-in-the-blank fields
- 3–4 iteration tips (practical, specific, drawn from the through-line)
- A "test it" instruction — paste into AI, see the difference

### 5. CFU-2 (Second Check for Understanding)
A design or application task — harder than CFU-1. The teacher identifies what's missing, designs something, or makes a judgment call. Uses the through-line project in Tiers 1–2, the teacher's own work in Tier 3.

### 6. The Reflection (Closing Connection)
Not a recap. Not a summary. A door.
- Name what they've built so far (Constitution section, unit component, etc.)
- Connect to the next course: what it adds and why it matters
- One specific thing to do between now and the next course
- End with an observation or question that sticks — something they'll think about later

---

## THE THROUGH-LINE PROJECT

Every example in Tiers 1 and 2 uses the same classroom. This is the demonstration project — the one that deepens across six courses. Don't restart with new examples. Build on what's already been established.

### The Classroom
- **School:** Lincoln High School
- **Course:** 10th grade SDC (Special Day Class) Science
- **Students:** 8 IEP students, mixed grade levels
- **Reading levels:** 6th–10th grade range
- **EL students:** Some emerging/developing
- **Groups:** Students work in groups of 3–4
- **Scaffolds:** Visual supports, vocabulary pre-teaching, sentence frames are standard
- **Period:** ~50 minutes

### The Project
- **Topic:** Hydroponics and community food access
- **Driving question:** "How can we grow food that feeds our neighborhood?"
- **Timeline:** 16 weeks (may reference as 14 in some prompts — either is fine)
- **Cost:** $1,100 custom-built systems (vs. $5,000 commercial kits)
- **Final product:** Community presentation with live plant data + harvest donation to the Third Street community fridge

### The Project Arc (6 Phases)

| Phase | Weeks | Focus |
|-------|-------|-------|
| Engineering Foundations | 1–3 | Problem definition, design comparison, prototype build |
| Physics of Systems | 4–6 | Energy transfer, flow rate, stability and troubleshooting |
| Biology of Growth | 7–8 | Photosynthesis, plant needs, connecting health to conditions |
| Chemistry of Solutions | 9–10 | Nutrients, pH, measuring and adjusting |
| Matter, Systems & Resilience | 11–12 | Where plant mass comes from, cycling, responding to disturbances |
| Optimization & Sustainability | 13–15 | Revision, impact analysis, defending design decisions |

Week 16 is community presentations + harvest donation.

### Key Details to Reference Across Courses
- Students chose butterhead lettuce and collard greens (some courses may also reference basil or peppers)
- pH baseline readings were completed early in the project
- Students built their own hydroponic frames
- The community fridge coordinator cares about reliability and volume
- The school board is the annual showcase audience — they care about learning evidence
- Parent volunteers help in the garden and want to see student ownership
- Students are growing food for a real community, for real people — this isn't hypothetical
- NGSS standards are embedded across all phases

### How the Project Deepens
- **Course 1 (Constraints):** Use the Week 5 moment — students are moving from pH readings to nutrient delivery design. Show how constraints about project phase, prior work, and differentiation change AI output.
- **Course 2 (Role Assignment):** Introduce the stakeholders — community fridge coordinator, school board, parent volunteers. Show how role prompts change what AI notices and critiques.
- **Course 3 (Iteration):** Use the Constitution itself as the iteration target. Test it, see what AI produces, refine the Constitution sections.
- **Course 4 (Meta-Prompting):** Stress-test the unit concept. Use meta-prompts to find gaps in the hydroponics arc — skill gaps, pacing risks, scaffolding holes.
- **Course 5 (Persona Calling):** Students as environmental consultants investigating food access for their neighborhood. Design the persona with real constraints and audience.
- **Course 6 (Workflow Design):** Map when students use AI during the project — research conversations, feedback loops, prototype sprints. Build reusable templates.

### Tier 3 Shift
In Tier 3 (Courses 7–10), STOP using the hydroponics demonstration example. Every example asks the teacher to apply the skill to their OWN Constitution or PBL unit. The shift from "here's a demo" to "now do it with yours" is the hallmark of actualization.

---

## THE EXAMPLE CONSTITUTION

This is the model Constitution that gets built progressively across Tier 1. By the end of Course 3, the teacher has seen this entire document take shape — and has built their own alongside it.

Show sections of this progressively:
- **Course 1** reveals Sections 1 and 2
- **Course 2** adds Section 3
- **Course 3** adds Section 4 and refines the whole document

```
You are assisting a teacher with the following classroom context. Use this
information to make every output specific, relevant, and classroom-ready.

CLASSROOM: 10th grade SDC Science at Lincoln High. 28 students, mixed
reading levels (6th-10th grade). 8 EL students (emerging/developing).
Students work in groups of 3-4. Visual scaffolds and vocabulary support
are standard.

CURRENT PROJECT: Hydroponics and community food access.
Driving question: How can we grow food that feeds our neighborhood?
Timeline: 14 weeks, currently Week 5.
Completed: pH baseline readings, system construction, plant selection.
Next: Nutrient delivery system design.
Final product: Community presentation with live plant data + harvest
donation to the Third Street community fridge.

STAKEHOLDERS: Community fridge coordinator (cares about reliability and
volume). School board (annual showcase audience, cares about student
learning evidence). Parent volunteers (help in garden, want to see
student ownership).

QUALITY STANDARDS: Activities take 30-50 min and build on prior work.
Materials must reference specific student data and project milestones.
4-point rubric scale. Scaffolds for EL students in every assignment.
Everything connects to the driving question.
```

A teacher who loads this into any AI tool will get dramatically better outputs without rethinking their prompt each time. That's the whole point.

---

## CFU DESIGN

Each course contains two CFUs and one workshop.

### CFU Voice
A CFU should sound like a colleague turning to you and saying, *"Okay, but which one would you actually use?"*

Not precious. Not gamified. Not "Great job, now let's test your knowledge!" Natural and direct.

- Frame it as a real decision: *"You're prepping for tomorrow. Which of these prompts gets you something usable?"*
- Explanations after answering should teach, not scold: *"The first one sounds reasonable, but notice it doesn't tell the AI what students already know. That's why the output would start from scratch."*
- Wrong-answer feedback should be generous: acknowledge why the wrong answer was tempting, then show what's missing.

### CFU Types Available
Use these formats. Match the type to what the course is teaching:

- **Prompt comparison:** Two prompts side by side — pick the one that works. Annotate both to show why. (Best for: Constraints, Role Assignment, Meta-Prompting, Critical Evaluation)
- **Identify-missing:** A weak prompt or draft — spot what's missing. Includes red herrings (things that seem missing but aren't). (Best for: Constraints, Workflow Design, Critical Evaluation)
- **Sequence ordering:** Steps to put in the right order. (Best for: Iteration)
- **Output matching:** Match prompts to their predicted outputs. (Best for: Iteration, Role Assignment)
- **Spot-the-difference:** Before/after prompt — click on what changed and why. (Best for: Meta-Prompting)
- **Bias spotter:** AI output with segments to evaluate for bias/accuracy. (Best for: Critical Evaluation)
- **Prompt remix:** Adapt a prompt from one context to another — identify what changes and what stays. (Best for: Iteration, Persona Calling)
- **Design task:** The teacher writes or designs something (a role prompt, a persona, a workflow step, an activity). (Best for: Role Assignment, Persona Calling, Workflow Design, Student AI Activities)

### CFU Content Rules
- Every CFU uses the through-line project (Tiers 1–2) or the teacher's own work (Tier 3)
- CFU-1 tests the mental model that was just taught
- CFU-2 is harder — it requires application or design
- No generic or hypothetical scenarios
- Every option (right and wrong) should feel plausible — the distinction is in specificity, not in obviously bad vs. good

---

## THE COMPLETE COURSE FRAMEWORK

This is the blueprint. Every learning outcome, deliverable, assessment, misconception, and connection is specified below. Follow it precisely — the accumulation model depends on each course building exactly what the framework describes.

### TIER 1 — FOUNDATION: Constraint, Context & Calibration

**What teachers are developing:** The ability to speak AI's language. AI outputs are only as good as the inputs you give it. This tier teaches teachers how to define their classroom with precision — and to capture that definition in a living document (the Classroom Constitution) that they will use to train AI going forward.

**The Constitution is modeled after Anthropic's own Constitutional AI approach:** a principled, values-based document that shapes how AI responds. This is an intentional design choice — and naming it builds teacher trust in AI systems.

**Why build a Constitution?** Constitutional prompting gives AI a reference document — values, constraints, context — it can refer back to before generating anything. Instead of re-explaining your classroom every time you open a new chat, you paste your Constitution in once and AI uses it to guide everything: tone, examples, scaffolds, complexity. The difference between telling a substitute your rules every period versus handing them a one-page guide at the start of the day.

---

#### COURSE 1: CONSTRAINTS

**What it teaches:** AI needs specificity to be useful. Generic prompts produce generic outputs. Constraints are how you tell AI what makes your classroom unique — the context that transforms a generic tool into a useful collaborator.

**Learning outcome:** Teachers can identify and articulate the 5 key constraints (project phase, prior student work, time box, differentiation needs, final product connection) and write them into their Constitution.

**Deliverable:** Constitution Sections 1 & 2
- Section 1: Classroom Context (grade, class size, reading levels, EL/IEP needs, scaffolds, period length, district requirements)
- Section 2: Project Architecture (project topic, driving question, timeline, milestones completed, what's next, final product, audience, disciplines)

**Assessment:**
- CFU-1: Prompt comparison — choose the constrained prompt over the generic one
- CFU-2: Identify-missing — spot 3+ missing constraints in a weak Constitution draft
- Workshop: Write their own Constitution Sections 1 & 2 and test with real AI

**Misconceptions to address:**
- "More words = better constraints" (quality and specificity over quantity)
- "This is extra work" (it saves time by reducing iterations)
- "I only need to do this once" (the Constitution evolves as the project evolves)

**Connection to Course 2:** The Constitution now knows your classroom and your project. Course 2 teaches you who else should be in the room — which stakeholders AI should speak as.

---

#### COURSE 2: ROLE ASSIGNMENT

**What it teaches:** When you assign AI a role or persona, you activate different patterns of expertise and perspective. Roles don't just change tone — they change what AI notices, what it pushes back on, and what it prioritizes.

**Learning outcome:** Teachers can identify key stakeholders in their PBL project and write role prompts that simulate authentic perspectives (skeptical funding officer, community partner, subject matter expert, student advocate).

**Deliverable:** Constitution Section 3
- Stakeholder & Perspective Map: who matters in this project, what feedback they'd give, role prompts ready to use

**Assessment:**
- CFU-1: Prompt comparison — constrained role vs. generic feedback request
- CFU-2: Design a role prompt for a specific stakeholder in their actual project
- Workshop: Map actual stakeholders and write 3 reusable role prompts

**Misconceptions to address:**
- "Roles are just about tone" (they change what AI attends to and critiques)
- "I'll only use one role" (different project phases need different stakeholder voices)
- "My students won't understand role-based AI" (students respond powerfully to clear perspectives)

**Connection to Course 3:** Rich Constitution (Sections 1–3). Course 3 teaches iterative refinement — treating the first output as a prototype, not a final product.

---

#### COURSE 3: ITERATION & QUALITY STANDARDS

**What it teaches:** Your first prompt is a prototype, not a final product. Iteration is not failure — it is the protocol. Teaches structured critique and defining "good" in advance.

**Learning outcome:** Teachers can generate, critique, and refine AI outputs using a structured protocol. They define their own quality standards for AI outputs.

**Deliverable:** Constitution Section 4
- Quality Standards: what "ready" means, what "good" looks like, how to critique
- Refined versions of Sections 1–3 based on real testing

**Assessment:**
- CFU-1: Critique protocol — given mediocre AI output, identify what to ask AI to fix
- CFU-2: Iteration plan — given feedback, rewrite the prompt rather than starting over
- Workshop: Test their full Constitution with real AI and iterate to classroom-ready

**Misconceptions to address:**
- "If the output is bad, I need a better prompt from scratch" (targeted critique is faster)
- "Iteration takes longer than starting over" (it's usually faster and more precise)
- "Accept the first output or ask for a complete redo" (the middle ground of critique is the most powerful skill)

**Tier 1 Closing:** Complete, tested AI Classroom Constitution — classroom context, project architecture, stakeholder map, quality standards. This is the input for everything in Tier 2.

---

### TIER 2 — APPLICATION: PBL Design with AI

**What teachers are developing:** The ability to use their Constitution as a launching pad to co-design a full, teach-ready PBL unit with AI. Every prompt is productive toward the deliverable. The unit is real — the teacher's actual unit.

**The Constitution is submitted to AI at the start of every course session.** It is not optional context. It is the operating document.

---

#### COURSE 4: META-PROMPTING (Unit Architecture)

**What it teaches:** Using AI to stress-test your own thinking — asking "What's missing?" and "How would this fail?" before investing in execution.

**Learning outcome:** Teachers can use meta-prompts to interrogate their emerging PBL unit — identify gaps, anticipate student struggle, surface overlooked design decisions.

**Deliverable:** A complete PBL unit outline, stress-tested by AI
- Driving question, project arc, assessment approach, scaffolds, connection points

**Assessment:**
- CFU-1: Meta-prompt comparison — generic design request vs. one that asks AI to find gaps
- CFU-2: Gap analysis — given a unit outline, write 3 meta-prompts to strengthen it
- Workshop: Stress-test their actual unit outline with AI

**Misconceptions to address:**
- "AI will design a better unit than I can" (AI surfaces options; the teacher decides)
- "I should accept AI's critique as correct" (it's a thinking partner, not a verdict)
- "Meta-prompting is for experts" (most useful for teachers new to PBL design)

**Connection to Course 5:** The unit has architecture. Course 5 adds the human element — who are students in this unit?

---

#### COURSE 5: PERSONA CALLING (Student Role Design)

**What it teaches:** When students take on a role with real constraints and a real audience, the work becomes meaningful. Designing authentic student personas grounded in the unit's driving question.

**Learning outcome:** Teachers can design personas (environmental consultant, community advocate, engineer, journalist) connected to the driving question, real-world constraints, and a defined audience.

**Deliverable:** Persona section of the PBL unit
- Roles, constraints, audience, connection to driving question

**Assessment:**
- CFU-1: Persona comparison — surface persona vs. one with real constraints and audience
- CFU-2: Write a persona prompt for their actual project
- Workshop: Design 1–2 personas and test how AI responses change

**Misconceptions to address:**
- "Persona = costume" (role-based constraints and decision-making, not performance)
- "This limits what students can do" (constraints enable better thinking)
- "Students will be confused" (students want clarity about what they're supposed to do)

**Connection to Course 6:** The unit has personas. How do students actually interact with AI while in that role? That's workflow design.

---

#### COURSE 6: WORKFLOW DESIGN (Student AI Integration)

**What it teaches:** The difference between "give students AI and hope" and designing explicit, repeatable processes for when and how students engage with AI.

**Learning outcome:** Teachers can map specific AI-use moments in their unit, design workflows, and create reusable templates.

**Deliverable:** Workflow section of the PBL unit
- When students use AI, workflow templates, student-facing prompts/frames, success criteria

**Assessment:**
- CFU-1: Workflow comparison — ad-hoc vs. systematic AI use
- CFU-2: Identify workflow gaps in a project arc
- Workshop: Design 2–3 workflows for their project, test one with real AI

**Misconceptions to address:**
- "Workflows constrain student thinking" (they enable independent thinking by removing decision fatigue)
- "Students will game it" (clear structures reduce gaming)
- "I need unique workflows for every task" (reusable templates are more sustainable)

**Tier 2 Closing:** Complete, AI-integrated PBL unit — driving question, unit arc, student personas, student-facing workflows. Tier 3 asks: how do we help students think well about AI as a tool?

---

### TIER 3 — ACTUALIZATION: Critical Judgment, Student Integration & Curriculum Vision

**What teachers are developing:** The highest-order skills. Evaluating, designing, and visioning. Reading AI use with nuance, designing activities that require students to think WITH AI, and auditing curriculum for high-leverage integration.

**Every example references the teacher's Constitution or PBL unit. No new hypothetical projects. No arbitrary examples. The shift from demo to "now do it with yours" is the hallmark of this tier.**

---

#### COURSE 7: CRITICAL EVALUATION

**What it teaches:** Evaluating AI outputs — scaffolding critical evaluation so students become active, skeptical consumers, not passive acceptors.

**Learning outcome:** Design prompts and rubrics that help students ask: Is this accurate? Is it original? Does it answer my actual question? Have I thought about this, or is AI doing my thinking?

**Deliverable:** Evaluation framework embedded in the PBL unit
- Student-facing rubric, teacher prompts, integration points in workflows

**Assessment:**
- CFU-1: Framework comparison — surface evaluation vs. one that teaches critical thinking
- CFU-2: Design an evaluation moment for a workflow step in their unit
- Workshop: Create a student-facing rubric for their unit, test with AI output

**Misconceptions to address:**
- "Students trust AI too much" (evaluation is the antidote, not restriction)
- "Evaluation slows things down" (built into workflows, it's fast and productive)
- "I need to evaluate for them" (student-led evaluation develops metacognition)

**Connection to Course 8:** Critical Evaluation teaches students to think about AI outputs. Course 8 addresses the teacher's side — reading student work.

---

#### COURSE 8: DETECTING AI WORK

**What it teaches:** Distinguishing between original work, appropriate AI-assisted work, over-reliance, and filler. Teaching response — not just detection.

**Learning outcome:** Teachers distinguish four categories and respond appropriately: (1) original work, (2) AI-assisted thinking, (3) AI-replaced thinking, (4) AI-generated filler. They design assessments that make AI use visible and intentional.

**Deliverable:** Detection & response framework tied to the PBL unit

**Assessment:**
- CFU-1: Sample analysis — identify category of AI use in student work
- CFU-2: Response scenario — celebrate, coach, or redesign
- Workshop: Write 1:1 conversation starters for ambiguous cases

**Misconceptions to address:**
- "If I see AI, the student did something wrong" (context matters)
- "I can always tell" (you can't, but patterns reveal intention)
- "I have to ban AI to maintain integrity" (transparent use is more honest than prohibition)

**Connection to Course 9:** Detecting is reading and responding. Course 9 is designing — building AI use into learning intentionally.

---

#### COURSE 9: STUDENT AI ACTIVITIES

**What it teaches:** Designing activities where students use AI to learn, not instead of learning. Activities live inside workflows (Course 6) and are anchored to the unit's driving question.

**Learning outcome:** Design targeted AI-powered activities that develop research skills, evaluative thinking, iterative revision, and metacognition — connected to explicit learning outcomes.

**Deliverable:** 2–3 AI-powered activity designs embedded in the PBL unit

**Assessment:**
- CFU-1: Activity quality — shallow AI use vs. deep learning design
- CFU-2: Align activity to learning target
- Workshop: Design one activity where students use AI to learn, connected to a specific outcome

**Misconceptions to address:**
- "AI activities are for advanced students" (especially powerful for struggling learners)
- "Using AI means students don't think" (well-designed activities make thinking visible)
- "I need an AI activity for every unit" (one solid activity is better than many shallow ones)

**Connection to Course 10:** Course 9 teaches AI within a unit. Course 10 asks: how do we think about AI across a whole curriculum?

---

#### COURSE 10: CURRICULUM AI DESIGN

**What it teaches:** The capstone. Thinking systematically about where AI fits across a whole course or curriculum — where it amplifies thinking, where it's unnecessary, and how to build toward it over 3–5 years. The Tier 2 unit becomes a proof of concept.

**Learning outcome:** Audit a course or curriculum, identify high-leverage AI integration moments, sketch a 3–5 year roadmap.

**Deliverable:** Curriculum audit + redesign framework

**Assessment:**
- CFU-1: Integration comparison — surface "add AI" vs. thoughtful "redesign for AI thinking"
- CFU-2: Curriculum audit — identify 3 high-leverage integration points
- Workshop: Audit one course, identify 3 AI opportunities, design one introduction

**Misconceptions to address:**
- "Every student uses AI constantly" (strategic, purposeful integration at key moments)
- "I need to redesign everything" (start with high-leverage moments, iterate over time)
- "AI will replace me" (AI amplifies what you already do well)

**Capstone Reflection:** Teachers leave with a critical evaluation framework, detection protocol, 2–3 AI-powered activities, and a curriculum roadmap — all grounded in their Constitution and unit.

---

## CROSS-COURSE PRINCIPLES

Follow these throughout all 10 courses:

1. **Accumulation:** Each course adds to the previous. Tier 1 builds the Constitution. Tier 2 uses it to build a unit. Tier 3 uses both to think about curriculum and student learning. Nothing is throwaway.

2. **Concreteness:** Every example, every CFU, every workshop uses either the teacher's Constitution, their PBL unit, or their actual classroom context. No arbitrary examples are introduced at any point.

3. **Feedback loops:** Every course includes a live workshop where teachers test their thinking with actual AI. This is not theoretical work.

4. **Constraints = clarity:** The through-line is that specificity and constraints enable better AI use — they don't constrain it. A teacher who writes vague prompts gets vague outputs. A teacher who brings their Constitution gets a collaborator.

5. **Iteration as mindset:** Not just in Course 3 — throughout. First draft, test, refine, repeat. Applies to the Constitution, the unit, the activities, and the curriculum roadmap.

6. **Trust through transparency:** Teachers who understand how AI works — constitutional training, role assignment, iteration — develop genuine, calibrated trust. The goal is not AI enthusiasm. It is AI fluency.

---

## WRITING RULES

- **The Constitution is sacred.** Every course in Tier 2 and 3 begins with teachers submitting their Constitution to AI. It is not optional context. It is the operating document.

- **Use the same through-line project throughout Tiers 1 and 2.** The hydroponics project deepens — it doesn't restart. Teachers see the same classroom scenario get richer and more powerful with each new skill.

- **In Tier 3, stop using the demonstration example.** Every example asks teachers to apply the skill to their own unit or Constitution. The shift from "here's a demo" to "now do it with yours" is intentional and essential.

- **Connect explicitly.** Don't assume teachers remember what they learned before. Start each course with: "In [previous course], you built X. Now we're adding Y because..."

- **Make failure visible.** Before-and-after examples aren't enough. Show the process of recognizing a weak prompt and improving it — the middle ground between accepting a bad output and starting over.

- **End with a door, not a wall.** Every course ending should make the teacher want to start the next one. Give them something to try between courses. Don't recap — open.

- **Every sentence earns its place.** If it doesn't teach, surprise, or carry the reader forward, cut it. The writing should feel smooth — one idea leading naturally into the next, the reader too engaged to notice the craft.
